{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "46858287-baa5-4dd5-b12a-19b570ab1b89",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Paramters - Databricks Widgets: \n",
    "For more information about widgets see [Databricks Widgets Documentation](https://docs.databricks.com/en/notebooks/widgets.html)\n",
    "\n",
    "Exemplatory notebook: [widgets](./widgets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "541c36a7-ce25-4d01-8314-75db4a3257fb",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Widgets"
    }
   },
   "outputs": [],
   "source": [
    "catalogs_df = spark.sql(\"SHOW CATALOGS\")\n",
    "catalog_names: list[str] = [row.catalog for row in catalogs_df.collect()]\n",
    "dbutils.widgets.dropdown(\n",
    "    name=\"catalog_name\",\n",
    "    defaultValue=catalog_names[0] if catalog_names else \"\",\n",
    "    choices=catalog_names if catalog_names else [\"\"],\n",
    "    label=\"Catalog Name\",\n",
    ")\n",
    "dbutils.widgets.text(\n",
    "    name=\"schema_name\",\n",
    "    defaultValue=\"\",\n",
    "    label=\"Schema Name\",\n",
    ")\n",
    "dbutils.widgets.text(\n",
    "    name=\"volume_name\",\n",
    "    defaultValue=\"\",\n",
    "    label=\"Volume Name\",\n",
    ")\n",
    "CATALOG_NAME: str = dbutils.widgets.get(\"catalog_name\")\n",
    "SCHEMA_NAME: str = dbutils.widgets.get(\"schema_name\")\n",
    "VOLUME_NAME: str = dbutils.widgets.get(\"volume_name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b54199a-5139-4846-88cd-b7576313f59b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### ! Make sure the output-volume exists.\n",
    "\n",
    "For more information about creating volumes see [Databricks Volumes Documentation](https://docs.databricks.com/en/volumes/index.html)\n",
    "\n",
    "Exemplatory notebook: [volumes](./volumes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "58bd95de-695b-4d2c-95dd-ff47d9df3779",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Exporting Table Data to XML\n",
    "\n",
    "Exports can be made on multiple platforms and methods, including:\n",
    "\n",
    "- **PySpark DataFrameWriter**: Use `.write.format(\"xml\")` to export DataFrames to XML.\n",
    "- **Databricks SQL**: Use the `TO_XML()` function to convert struct or variant columns to XML strings.\n",
    "- **Scala DataFrameWriter**: Similar to the PySpark DataFrameWriter.\n",
    "- **R DataFrameWriter**: Use `saveDF()` with XML format in R notebooks.\n",
    "\n",
    "Each method supports options for customizing XML output, such as `rootTag` and `rowTag`.\n",
    "\n",
    "Exports normally take place in the final layer, like the `gold` or `product` layer.\n",
    "\n",
    "![Export architecture diagram](../resources/export-architecture.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7d73f084-23ee-4dbe-9f5d-ea13ce5c5bee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## PySpark export example\n",
    "\n",
    "1. **Read the table into a DataFrame**  \n",
    "   Use Spark to load your table:  \n",
    "   ```python\n",
    "   data_frame = spark.table(\"catalog_name.schema_name.table_name\")\n",
    "   ```\n",
    "\n",
    "2. **Write the DataFrame as XML**  \n",
    "   Use the XML data source:  \n",
    "   ```python\n",
    "   data_frame.write \\\n",
    "       .format(\"xml\") \\\n",
    "       .options(rootTag=\"trips\", rowTag=\"trip\") \\\n",
    "       .mode(\"overwrite\") \\\n",
    "       .save(\"/Volumes/catalog_name/schema_name/volume_name/output.xml\")\n",
    "   ```\n",
    "\n",
    "- Adjust `rootTag` and `rowTag` for your schema.\n",
    "- The output XML file will be saved to your specified Unity Catalog volume.\n",
    "\n",
    "See [Spark XML Documentation](https://spark.apache.org/docs/latest/sql-data-sources-xml.html) for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "9a4dcbe4-027d-481d-a13f-1e1ae459ef9e",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Helper function to display generated XML files"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "def get_first_xml_file(directory_path: str) -> str:\n",
    "    \"\"\"Return the full path of the first XML file found in the given directory.\"\"\"\n",
    "    for file_name in os.listdir(directory_path):\n",
    "        if file_name.lower().endswith(\".xml\"):\n",
    "            return os.path.join(directory_path, file_name)\n",
    "    raise FileNotFoundError(\"No XML file found in the specified directory.\")\n",
    "\n",
    "def displayXML(xml_path: str) -> None:    \n",
    "    \"\"\"Show the content of an XML file\"\"\"\n",
    "    if xml_path.lower().endswith(\".xml\"):\n",
    "        selected_xml_file_path: str = xml_path\n",
    "    else:\n",
    "        selected_xml_file_path: str = get_first_xml_file(xml_path)\n",
    "    with open(selected_xml_file_path, \"r\", encoding=\"utf-8\") as xml_file:\n",
    "        raw_xml_content: str = \"\".join([xml_file.readline() for _ in range(100)])\n",
    "    print(raw_xml_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "03501d28-ae08-4a94-a762-416c1711acf3",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "PySpark Simple Example"
    }
   },
   "outputs": [],
   "source": [
    "# This cell illustrates how a complete table can be exported to XML based on a simple structure.\n",
    "\n",
    "from pyspark.sql import DataFrame\n",
    "\n",
    "output_filename: str = \"nyctaxi_trips\"\n",
    "\n",
    "print(\"Selecting data from samples.nyctaxi.trips table...\")\n",
    "nyctaxi_trips_df: DataFrame = spark.sql(\"SELECT * FROM samples.nyctaxi.trips\")\n",
    "print(\"✅ Data selected.\")\n",
    "\n",
    "volume_path: str = f\"/Volumes/{CATALOG_NAME}/{SCHEMA_NAME}/{VOLUME_NAME}/{output_filename}\"\n",
    "print(f\"Writing XML data to volume: {volume_path} ...\")\n",
    "nyctaxi_trips_df.write \\\n",
    "  .format(\"xml\") \\\n",
    "  .options(rootTag=\"trips\", rowTag=\"trip\") \\\n",
    "  .mode(\"overwrite\") \\\n",
    "  .save(volume_path)\n",
    "print(\"✅ XML export complete.\")\n",
    "\n",
    "# Displaying the xml file to showcase the result.\n",
    "displayXML(volume_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "12f1f367-781d-4a65-8f90-b9bcc2d5cd90",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "PySpark Complex Example"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql.functions import collect_list, struct, col, substring\n",
    "\n",
    "output_foldername: str = \"bakehouse_franchises_complex\"\n",
    "volume_path: str = (\n",
    "    f\"/Volumes/{CATALOG_NAME}/{SCHEMA_NAME}/{VOLUME_NAME}/{output_foldername}\"\n",
    ")\n",
    "\n",
    "# Base tables\n",
    "transactions_df: DataFrame = (\n",
    "    spark.table(\"samples.bakehouse.sales_transactions\")\n",
    "    .select(\n",
    "        col(\"transactionID\"),\n",
    "        col(\"dateTime\"),\n",
    "        col(\"quantity\"),\n",
    "        col(\"product\"),\n",
    "        col(\"customerID\"),\n",
    "        col(\"franchiseID\"),\n",
    "    )\n",
    ")\n",
    "customers_df: DataFrame = (\n",
    "    spark.table(\"samples.bakehouse.sales_customers\")\n",
    "    .select(\n",
    "        col(\"customerID\"),\n",
    "        col(\"last_name\").alias(\"customer_name\"),\n",
    "        col(\"email_address\"),\n",
    "        col(\"phone_number\"),\n",
    "    )\n",
    "    .filter(col(\"email_address\").isNotNull())\n",
    ")\n",
    "franchises_df: DataFrame = (\n",
    "    spark.table(\"samples.bakehouse.sales_franchises\")\n",
    "    .select(\n",
    "        col(\"franchiseID\"),\n",
    "        col(\"name\").alias(\"franchise_name\"),\n",
    "        col(\"city\"),\n",
    "        col(\"district\"),\n",
    "        col(\"zipcode\"),\n",
    "        col(\"country\"),\n",
    "        col(\"size\"),\n",
    "        col(\"longitude\"),\n",
    "        col(\"latitude\"),\n",
    "        col(\"supplierID\"),\n",
    "    )\n",
    ")\n",
    "\n",
    "# Enrich transactions with nested children\n",
    "tx_nested_df: DataFrame = (\n",
    "    transactions_df.alias(\"t\")\n",
    "    .join(customers_df.alias(\"c\"), col('t.customerID').substr(2, 100) == col('c.customerID').substr(2, 100), how=\"inner\")\n",
    "    .join(franchises_df.alias(\"f\"), on=\"franchiseID\", how=\"inner\")\n",
    "    .select(\n",
    "        col(\"t.transactionID\").alias(\"transactionID\"),\n",
    "        col(\"t.dateTime\").alias(\"dateTime\"),\n",
    "        col(\"t.quantity\").alias(\"quantity\"),\n",
    "        col(\"t.product\").alias(\"product\"),\n",
    "        struct(\n",
    "            col(\"c.customerID\").alias(\"id\"),\n",
    "            col(\"c.customer_name\").alias(\"name\"),\n",
    "            struct(\n",
    "                col(\"c.email_address\").alias(\"email\"),\n",
    "                col(\"c.phone_number\").alias(\"phone\"),\n",
    "            ).alias(\"contact_info\"),\n",
    "        ).alias(\"customer\"),\n",
    "        struct(\n",
    "            col(\"f.franchiseID\").alias(\"id\"),\n",
    "            col(\"f.franchise_name\").alias(\"name\"),\n",
    "            col(\"f.city\").alias(\"city\"),\n",
    "            col(\"f.district\").alias(\"district\"),\n",
    "            col(\"f.zipcode\").alias(\"zipcode\"),\n",
    "            col(\"f.country\").alias(\"country\"),\n",
    "            col(\"f.size\").alias(\"size\"),\n",
    "            col(\"f.longitude\").alias(\"longitude\"),\n",
    "            col(\"f.latitude\").alias(\"latitude\"),\n",
    "            col(\"f.supplierID\").alias(\"supplierID\"),\n",
    "        ).alias(\"franchise\"),\n",
    "    )\n",
    ")\n",
    "\n",
    "# Write nested XML\n",
    "(\n",
    "    tx_nested_df.write\n",
    "    .format(\"xml\")\n",
    "    .options(rootTag=\"transactions\", rowTag=\"transaction\")\n",
    "    .mode(\"overwrite\")\n",
    "    .save(volume_path)\n",
    ")\n",
    "\n",
    "print(\"✅ XML export complete.\")\n",
    "\n",
    "# Displaying the xml file to showcase the result.\n",
    "displayXML(volume_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8005d0ab-996e-4296-b779-0f76cc3d0f07",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Databricks SQL Example\n",
    "\n",
    "1. **Read the table using SQL**  \n",
    "   Use a SQL query to select your data:  \n",
    "\n",
    "   ```sql\n",
    "   SELECT * FROM :catalog_name.:schema_name.:table_name\n",
    "   ```\n",
    "\n",
    "2. **Export the data to XML using TO_XML()**  \n",
    "   Use the `TO_XML()` function to convert rows to XML strings:  \n",
    "\n",
    "   ```sql\n",
    "   SELECT TO_XML(\n",
    "       struct(*),\n",
    "       'trips',    -- rootTag\n",
    "       'trip'      -- rowTag\n",
    "   ) AS xml_data\n",
    "   FROM :catalog_name.:schema_name.:table_name\n",
    "   ```\n",
    "\n",
    "3. **Save the XML output to a Unity Catalog volume**  \n",
    "   Use the `COPY INTO` command to write the XML data to your volume:  \n",
    "   \n",
    "   ```sql\n",
    "   COPY INTO '/Volumes/:catalog_name/:schema_name/:volume_name/output.xml'\n",
    "   FROM (\n",
    "       SELECT TO_XML(\n",
    "           struct(*),\n",
    "           'trips',\n",
    "           'trip'\n",
    "       ) AS xml_data\n",
    "       FROM :catalog_name.:schema_name.:table_name\n",
    "   )\n",
    "   FILEFORMAT = TEXT\n",
    "   ```\n",
    "   \n",
    "- Adjust `rootTag` and `rowTag` for your schema.\n",
    "- The output XML file will be saved to your specified Unity Catalog volume.\n",
    "\n",
    "See [TO_XML() documentation](https://docs.databricks.com/en/sql/language-manual/functions/to_xml.html) for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cfd70bef-76bf-4ec7-825c-0213c9241ee4",
     "showTitle": true,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{\"xml_output_path\":563},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1762528603583}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": "Databricks SQL Complex Example"
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "\n",
    "DECLARE OR REPLACE xml_output_path STRING;\n",
    "SET VAR xml_output_path = CONCAT('dbfs:/Volumes/',:catalog_name,'/',:schema_name,'/',:volume_name,'/bakehouse_franchises_complex_sql');\n",
    "\n",
    "DECLARE OR REPLACE sql_fqn STRING;\n",
    "SET VAR sql_fqn = CONCAT(:catalog_name, '.', :schema_name, '._tmp_xml_output');\n",
    "\n",
    "-- Create temporary table to simplify parameterization.\n",
    "CREATE OR REPLACE TABLE IDENTIFIER(sql_fqn)\n",
    "AS \n",
    "SELECT\n",
    "        TO_XML(\n",
    "            named_struct(\n",
    "            'transactionID', t.transactionID,\n",
    "            'dateTime',      t.dateTime,\n",
    "            'quantity',      t.quantity,\n",
    "            'product',       t.product,\n",
    "            'customer', named_struct(\n",
    "                'id',           c.customerID,\n",
    "                'name',         c.last_name,\n",
    "                'contact_info', named_struct('email', c.email_address, 'phone', c.phone_number)\n",
    "            ),\n",
    "            'franchise', named_struct(\n",
    "                'id',         f.franchiseID,\n",
    "                'name',       f.name,\n",
    "                'city',       f.city,\n",
    "                'district',   f.district,\n",
    "                'zipcode',    f.zipcode,\n",
    "                'country',    f.country,\n",
    "                'size',       f.size,\n",
    "                'longitude',  f.longitude,\n",
    "                'latitude',   f.latitude,\n",
    "                'supplierID', f.supplierID\n",
    "            )\n",
    "            ),\n",
    "            map('rootTag','transaction')\n",
    "        ) AS xml_row\n",
    "        FROM samples.bakehouse.sales_transactions t\n",
    "        JOIN samples.bakehouse.sales_customers c\n",
    "            ON substr(cast(t.customerID AS string), 2) = substr(cast(c.customerID AS string), 2)\n",
    "        JOIN samples.bakehouse.sales_franchises f\n",
    "            ON t.franchiseID = f.franchiseID\n",
    "        WHERE c.email_address IS NOT NULL\n",
    "        LIMIT 100\n",
    ";\n",
    "\n",
    "-- Write temp table to txt file\n",
    "DECLARE OR REPLACE liststmt STRING;\n",
    "SET VAR liststmt = CONCAT('\n",
    "    INSERT OVERWRITE DIRECTORY \"',xml_output_path,'\"\n",
    "    USING TEXT\n",
    "    SELECT xml_row \n",
    "    FROM IDENTIFIER(sql_fqn)\n",
    "    ;');\n",
    "execute immediate liststmt ;\n",
    "\n",
    "-- Drop temp table\n",
    "DROP TABLE IF EXISTS IDENTIFIER(sql_fqn);\n",
    "\n",
    "-- Verify file creation\n",
    "SET VAR liststmt = CONCAT('LIST \"', xml_output_path, '\"');\n",
    "execute immediate liststmt ;\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 7545927419057132,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "export-to-xml",
   "widgets": {
    "catalog_name": {
     "currentValue": "poc_ai_claim_handler",
     "nuid": "e872f2cf-1692-43a0-a326-59398f7430fd",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "__databricks_internal",
      "label": "Catalog Name",
      "name": "catalog_name",
      "options": {
       "widgetDisplayType": "Dropdown",
       "choices": [
        "__databricks_internal",
        "airflow_dbx_brenntag",
        "connector_salesforce",
        "demos",
        "excel_app",
        "fieldkit",
        "fugro",
        "hive_metastore",
        "main",
        "poc_ai_claim_handler",
        "samples",
        "sat_catalog",
        "system",
        "zoetermeer"
       ],
       "fixedDomain": true,
       "multiselect": false
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "dropdown",
      "defaultValue": "__databricks_internal",
      "label": "Catalog Name",
      "name": "catalog_name",
      "options": {
       "widgetType": "dropdown",
       "autoCreated": null,
       "choices": [
        "__databricks_internal",
        "airflow_dbx_brenntag",
        "connector_salesforce",
        "demos",
        "excel_app",
        "fieldkit",
        "fugro",
        "hive_metastore",
        "main",
        "poc_ai_claim_handler",
        "samples",
        "sat_catalog",
        "system",
        "zoetermeer"
       ]
      }
     }
    },
    "schema_name": {
     "currentValue": "raw",
     "nuid": "77f16ad1-2240-4527-962f-5bd4178fd1e8",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": "Schema Name",
      "name": "schema_name",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": "Schema Name",
      "name": "schema_name",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "volume_name": {
     "currentValue": "test_xml_output",
     "nuid": "c434d12b-7ff7-434b-8b86-4095b6eb84fc",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": "Volume Name",
      "name": "volume_name",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": "Volume Name",
      "name": "volume_name",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
